{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1fb014-0a20-4207-909b-8250b7eb675b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc238869-cc8f-4653-b149-60aae0e5d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio import Seq\n",
    "import csv\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "def load_index (file,read_len = 151, trim = \"TCTGGTGGATCTGGAGGTCTCGA\", Fedit = \"\", Redit = \"\", rev = False):\n",
    "    \n",
    "    \"\"\" Loads in csv file in format of 1) ID 2) sequence as a sequnce cross check. Output is a refrence dictionary that is of form\n",
    "    {\"Seq\": (ID,count)} where ID is uniprot ID and goup assingment and count is defaulted to start at 0 reads mapped\"\"\"\n",
    "    \n",
    "    index = OrderedDict()\n",
    "    indexfull = []\n",
    "    with open(file,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        header,seqs = lines[0],lines[1:]\n",
    "        seqs_clean = [s.strip().split(',') for s in seqs]\n",
    "        \n",
    "        # For matching with reverse NGS reads, index is reformated with reverse compliment and trimmed sequences. \n",
    "        if rev:\n",
    "            for r in seqs_clean:\n",
    "                ID = r[0]\n",
    "                tempseq = r[1]\n",
    "                cutoff = tempseq.find(trim) #For matching with reverse NGS reads, index is reformated with reverse compliment data. \n",
    "                param = 151 - len(Fedit) - len(Redit)  #adust max index length parameter to account for NGS read length and with forward and reverse trims\n",
    "                \n",
    "                if len(tempseq) <= param: #Check if unique index sequence is less than total NGS read length\n",
    "                    fseq = Seq.Seq(Fedit + tempseq[cutoff:-1])  #Apply trims\n",
    "                    rseq = fseq.reverse_complement() #Take reverse compliment of fwd index sequence\n",
    "                \n",
    "                    index[Redit + str(rseq)] = [ID,0] #Create index entry\n",
    "                    indexfull.append(str(Redit + Seq.Seq(tempseq).reverse_complement())) #append full index in a list of sequence strings with no read trim\n",
    "                \n",
    "                else:  #If read is longer than NGS read length, trim from the given read direction to match read length for exact seq match\n",
    "                    fseq = Seq.Seq(tempseq[-151 + len(Redit):-1])\n",
    "                    rseq = fseq.reverse_complement()\n",
    "                                   \n",
    "                    index[Redit + str(rseq)] = [ID,0]\n",
    "                    indexfull.append(Redit + str(Seq.Seq(tempseq).reverse_complement()))\n",
    "                    \n",
    "        else:\n",
    "            Redit2 = str(Seq.Seq(Redit).reverse_complement())\n",
    "            for r in seqs_clean:\n",
    "                ID = r[0]\n",
    "                fseq = r[1][:-trim]\n",
    "                index[fseq] = [ID,0]\n",
    "        \n",
    "    return index,indexfull\n",
    "\n",
    "def process_fastq (fastq_file,fwd,rev,QCavg = 35, QCbase = 20):\n",
    "\n",
    "    \"\"\"Loads in FASTQ file of NGS reads data and identified known reverse-sequence region of interest and trims sequence\n",
    "    to only unique TMD region. Quality of region is determined from FASTQ data and assesses if data passes QC check\"\"\"\n",
    "    \n",
    "    f_ind = len(fwd) ## Defines forward trim length\n",
    "    qc_seq = [] ## Initialize list of accetable sequences at trimmed sequence\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(fastq_file,'rt') as f:\n",
    "            records = SeqIO.parse(f,'fastq') # Load in fastq files\n",
    "            for r in records:\n",
    "                r_ind = r.seq.find(rev) # find reverse handle in sequence, if not there assign -1\n",
    "                qual = r.letter_annotations['phred_quality'][f_ind:r_ind] # Call in quality scores for trimmed region\n",
    "                if np.mean(qual) >= QCavg: # Check the average quality is above threshold\n",
    "                    for q in qual:\n",
    "                        if q <= QCbase: # Check no outlier base is bad quality in mapped region, if so don't append\n",
    "                            er = 'False'\n",
    "                            break\n",
    "                        else:\n",
    "                            er = 'True'\n",
    "                    if er:\n",
    "                        qc_seq.append(str(r.seq[:r_ind]))\n",
    "                else:\n",
    "                    continue ## Or jump to next sequnce if QC condition is not met\n",
    "    except: \n",
    "        with open(fastq_file,'rt') as f:\n",
    "            records = SeqIO.parse(f,'fastq') # Load in fastq files\n",
    "            for r in records:\n",
    "                r_ind = r.seq.find(rev) # find reverse handle in sequence, if not there assign -1\n",
    "                qual = r.letter_annotations['phred_quality'][f_ind:r_ind] # Call in quality scores for trimmed region\n",
    "                if np.mean(qual) >= QCavg: # Check the average quality is above threshold\n",
    "                    for q in qual:\n",
    "                        if q <= QCbase: # Check no outlier base is bad quality in mapped region, if so don't append\n",
    "                            er = 'False'\n",
    "                            break\n",
    "                        else:\n",
    "                            er = 'True'\n",
    "                    if er:\n",
    "                        if r_ind > 0:\n",
    "                            qc_seq.append(str(r.seq[:r_ind + len(rev)])) ## Append good sequences to cleaned list\n",
    "                        else:\n",
    "                            qc_seq.append(str(r.seq[:r_ind]))\n",
    "                else:\n",
    "                    continue ## Or jump to next sequnce if QC condition is not met\n",
    "    return qc_seq,records\n",
    "        \n",
    "def map_seqs (qc_seqs,index,fullindex,fwd):\n",
    "    \n",
    "    \"\"\"Maps QC verified sequences to known sequence index for the given library with index defined in previous \n",
    "    function 'load_index'. Only exact sequence matches accepted for read counts.\"\"\"\n",
    "    \n",
    "    # Initialize read mapped categories and arrays\n",
    "    num_reads = 0\n",
    "    num_mapped = 0\n",
    "    num_unmapped = 0\n",
    "    no_fwd_handle = 0\n",
    "    mapped,unmapped,nohand = [],[],[]\n",
    "    \n",
    "    for s in qc_seqs:\n",
    "        num_reads += 1 #track total reads processed\n",
    "        \n",
    "        f_ind = s.find(fwd) #Find index of fwd handle to identify index-matched region\n",
    "        \n",
    "        if f_ind >= 0: #If fwd handle is found, look for sequence in the index and increase given index entry read count\n",
    "            \n",
    "            if s in index:\n",
    "                num_mapped += 1\n",
    "                mapped.append(s)\n",
    "                index[s][1] += 1\n",
    "                \n",
    "            else:  #If sequence is not matched with propper trims check for the sequence appearence in the full index to assign read count\n",
    "                for i,k in zip(index.keys(),fullindex):\n",
    "                    loc = re.search(s,k)\n",
    "                    if loc:\n",
    "                        num_mapped += 1\n",
    "                        index[i][1] += 1\n",
    "                        mapped.append(s)\n",
    "                        break\n",
    "                        \n",
    "                if not loc: #If no match found, move to next read and count sequence as unmapped\n",
    "                    num_unmapped += 1\n",
    "                    unmapped.append(s)\n",
    "        \n",
    "        else: #If fwd handle not found, ingore read\n",
    "            no_fwd_handle += 1\n",
    "            nohand.append(s)\n",
    "        \n",
    "    return index,num_reads,num_mapped,mapped,num_unmapped,unmapped,no_fwd_handle,nohand\n",
    "    \n",
    "def final_return(fileout,index1,index2 = {},num_reads = []):\n",
    "    \n",
    "    \"\"\"Writes final read data out to file\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(num_reads) < 1:\n",
    "        raise Exception(\"Please pass the number of reads as a list of [Rep1,Rep2]\")\n",
    "    if len(list(index2.keys())) > 0 and len(num_reads) < 2:\n",
    "        raise Exception(\"Please pass number of reads for BOTH replicates in a list\")\n",
    "        \n",
    "    index_temp = deepcopy(index1)\n",
    "    for k in index_temp.keys():\n",
    "        index_temp[k].append(index_temp[k][1]/num_reads[0])\n",
    "    \n",
    "    \n",
    "    output_df = pd.DataFrame.from_dict(index_temp,'index',columns = ['ID1','Read Count Rep 1','Read Norm Rep 1'])\n",
    "    \n",
    "    if len(list(index2.keys())) > 0:\n",
    "        rep_index = deepcopy(index2)\n",
    "        for k in rep_index.keys():\n",
    "            rep_index[k].append(rep_index[k][1]/num_reads[1])\n",
    "    \n",
    "        rep_df = pd.DataFrame.from_dict(rep_index,'index',columns = ['ID2','Read Count Rep 2','Read Norm Rep 2'])\n",
    "        rep_df_trim = rep_df.loc[:,'ID':'Read Norm Rep 2']\n",
    "        \n",
    "        output_df = output_df.join(rep_df_trim)\n",
    "    with open(fileout,'w') as f:\n",
    "        output_df.to_csv(f,index=True,index_label = \"Sequence\")\n",
    "    return \n",
    "\n",
    "def load_and_run(data_file, index, fullindex, fwd_handle = \"TCGAGACCTCCAGATCCACCAGA\", rev_handle = \"GCCCAGATCCTCTTCTGAGATGAG\",fwd_tag = \"\", rev_tag = \"\"):\n",
    "    \n",
    "    \"\"\"Compiled function to import fastq files and processes index and map read counts using previously defined funcitons.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add in stagger to handles in correct order\n",
    "    fwd_handle_new = fwd_tag + fwd_handle\n",
    "    rev_handle_new = rev_handle + str(Seq.Seq(rev_tag).reverse_complement())\n",
    "    \n",
    "    # Run QC with new handles\n",
    "    qc_seq,recs = process_fastq(data_file,fwd_handle_new,rev_handle_new)\n",
    "    index_updated,read_count,map_count,mapped,unmap_count,unmap,notfound_count,notfound = map_seqs(qc_seq,index, fullindex = fullindex, fwd = fwd_handle_new)\n",
    "    \n",
    "    print(f'Mapped % : {map_count/read_count}')\n",
    "    print(f'Unmapped % : {unmap_count/read_count}')\n",
    "    print(f'No Handle % : {notfound_count/read_count}')\n",
    "    \n",
    "    \n",
    "    return index_updated,read_count,map_count,mapped,unmap_count,unmap,notfound_count,notfound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9262a54-6de6-4521-acc3-6fc9ef0af435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
