{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1fb014-0a20-4207-909b-8250b7eb675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio import Seq\n",
    "import csv\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc238869-cc8f-4653-b149-60aae0e5d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index (file,read_len = 151, trim = \"TCTGGTGGATCTGGAGGTCTCGA\", Fedit = \"\", Redit = \"\", rev = False):\n",
    "    \n",
    "    \"\"\" Loads in csv file in format of 1) ID 2) sequence as a sequnce cross check. Output is a refrence dictionary that is of form\n",
    "    {\"Seq\": (ID,count)} where ID is uniprot ID and goup assingment and count is defaulted to start at 0 reads mapped\"\"\"\n",
    "    \n",
    "    index = OrderedDict()\n",
    "    indexfull = []\n",
    "    with open(file,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        header,seqs = lines[0],lines[1:]\n",
    "        seqs_clean = [s.strip().split(',') for s in seqs]\n",
    "        \n",
    "        # For matching with reverse NGS reads, index is reformated with reverse compliment data. \n",
    "        if rev:\n",
    "            for r in seqs_clean:\n",
    "                ID = r[0]\n",
    "                tempseq = r[1]\n",
    "                cutoff = tempseq.find(trim)# For matching with reverse NGS reads, index is reformated with reverse compliment data. \n",
    "                param = 151 - len(Fedit) - len(Redit) #adust max index length parameter to account for NGS read length and with forward and reverse trims\n",
    "                \n",
    "                if len(tempseq) <= param:\n",
    "                    fseq = Seq.Seq(Fedit + tempseq[cutoff:-1]) #Apply trims\n",
    "                    rseq = fseq.reverse_complement() #Take rev complement\n",
    "                \n",
    "                    index[Redit + str(rseq)] = [ID,0] #Create index entry\n",
    "                    indexfull.append(str(Redit + Seq.Seq(tempseq).reverse_complement())) #append full index in a list of sequence strings with no read trim\n",
    "                else:\n",
    "                    fseq = Seq.Seq(tempseq[-151 + len(Redit):-1]) #If read is longer than NGS read length, trim from the given read direction to match read length for exact seq match\n",
    "                    rseq = fseq.reverse_complement()\n",
    "                                   \n",
    "                    index[Redit + str(rseq)] = [ID,0]\n",
    "                    indexfull.append(Redit + str(Seq.Seq(tempseq).reverse_complement()))\n",
    "                    \n",
    "        else:\n",
    "            Redit2 = str(Seq.Seq(Redit).reverse_complement())\n",
    "            for r in seqs_clean:\n",
    "                ID = r[0]\n",
    "                fseq = r[1][:-trim]\n",
    "                index[fseq] = [ID,0]\n",
    "        \n",
    "    return index,indexfull\n",
    "\n",
    "def process_fastq (fastq_file,fwd,rev,QCavg = 35, QCbase = 20):\n",
    "\n",
    "    f_ind = len(fwd) ## Defines forward trim length\n",
    "    qc_seq = [] ## Initialize list of accetable sequences at trimmed sequence\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(fastq_file,'rt') as f:\n",
    "            records = SeqIO.parse(f,'fastq') # Load in fastq files\n",
    "            for r in records:\n",
    "                r_ind = r.seq.find(rev) # find reverse handle in sequence, if not there assign -1\n",
    "                qual = r.letter_annotations['phred_quality'][f_ind:r_ind] # Call in quality scores for trimmed region\n",
    "                if np.mean(qual) >= QCavg: # Check the average quality is above threshold\n",
    "                    for q in qual:\n",
    "                        if q <= QCbase: # Check no outlier base is bad quality in mapped region, if so don't append\n",
    "                            er = 'False'\n",
    "                            break\n",
    "                        else:\n",
    "                            er = 'True'\n",
    "                    if er:\n",
    "                        qc_seq.append(str(r.seq[:r_ind]))\n",
    "                else:\n",
    "                    continue ## Or jump to next sequnce if QC condition is not met\n",
    "    except: \n",
    "        with open(fastq_file,'rt') as f:\n",
    "            records = SeqIO.parse(f,'fastq') # Load in fastq files\n",
    "            for r in records:\n",
    "                r_ind = r.seq.find(rev) # find reverse handle in sequence, if not there assign -1\n",
    "                qual = r.letter_annotations['phred_quality'][f_ind:r_ind] # Call in quality scores for trimmed region\n",
    "                if np.mean(qual) >= QCavg: # Check the average quality is above threshold\n",
    "                    for q in qual:\n",
    "                        if q <= QCbase: # Check no outlier base is bad quality in mapped region, if so don't append\n",
    "                            er = 'False'\n",
    "                            break\n",
    "                        else:\n",
    "                            er = 'True'\n",
    "                    if er:\n",
    "                        if r_ind > 0:\n",
    "                            qc_seq.append(str(r.seq[:r_ind + len(rev)])) ## Append good sequences to cleaned list\n",
    "                        else:\n",
    "                            qc_seq.append(str(r.seq[:r_ind]))\n",
    "                else:\n",
    "                    continue ## Or jump to next sequnce if QC condition is not met\n",
    "    return qc_seq,records\n",
    "        \n",
    "def map_seqs (qc_seqs,index,fullindex,fwd):\n",
    "    \n",
    "    num_reads = 0\n",
    "    num_mapped = 0\n",
    "    num_unmapped = 0\n",
    "    no_fwd_handle = 0\n",
    "    mapped,unmapped,nohand = [],[],[]\n",
    "    \n",
    "    for s in qc_seqs:\n",
    "        num_reads += 1\n",
    "        \n",
    "        f_ind = s.find(fwd)\n",
    "        \n",
    "        if f_ind >= 0:\n",
    "            \n",
    "            if s in index:\n",
    "                num_mapped += 1\n",
    "                mapped.append(s)\n",
    "                index[s][1] += 1\n",
    "                \n",
    "            else:\n",
    "                for i,k in zip(index.keys(),fullindex):\n",
    "                    loc = re.search(s,k)\n",
    "                    if loc:\n",
    "                        num_mapped += 1\n",
    "                        index[i][1] += 1\n",
    "                        mapped.append(s)\n",
    "                        break\n",
    "                        \n",
    "                if not loc:\n",
    "                    num_unmapped += 1\n",
    "                    unmapped.append(s)\n",
    "        else:\n",
    "            no_fwd_handle += 1\n",
    "            nohand.append(s)\n",
    "        \n",
    "    return index,num_reads,num_mapped,mapped,num_unmapped,unmapped,no_fwd_handle,nohand\n",
    "\n",
    "def final_return(fileout,index1,index2 = {},num_reads = []):\n",
    "    \"\"\"Writes final read data out to file\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(num_reads) < 1:\n",
    "        raise Exception(\"Please pass the number of reads as a list of [Rep1,Rep2]\")\n",
    "    if len(list(index2.keys())) > 0 and len(num_reads) < 2:\n",
    "        raise Exception(\"Please pass number of reads for BOTH replicates in a list\")\n",
    "        \n",
    "    index_temp = deepcopy(index1)\n",
    "    for k in index_temp.keys():\n",
    "        index_temp[k].append(index_temp[k][1]/num_reads[0])\n",
    "    \n",
    "    \n",
    "    output_df = pd.DataFrame.from_dict(index_temp,'index',columns = ['ID1','Read Count Rep 1','Read Norm Rep 1'])\n",
    "    \n",
    "    if len(list(index2.keys())) > 0:\n",
    "        rep_index = deepcopy(index2)\n",
    "        for k in rep_index.keys():\n",
    "            rep_index[k].append(rep_index[k][1]/num_reads[1])\n",
    "    \n",
    "        rep_df = pd.DataFrame.from_dict(rep_index,'index',columns = ['ID2','Read Count Rep 2','Read Norm Rep 2'])\n",
    "        rep_df_trim = rep_df.loc[:,'ID':'Read Norm Rep 2']\n",
    "        \n",
    "        output_df = output_df.join(rep_df_trim)\n",
    "    with open(fileout,'w') as f:\n",
    "        output_df.to_csv(f,index=True,index_label = \"Sequence\")\n",
    "    return \n",
    "\n",
    "def load_and_run(data_file, index, fullindex, fwd_handle = \"TCGAGACCTCCAGATCCACCAGA\", rev_handle = \"GCCCAGATCCTCTTCTGAGATGAG\",fwd_tag = \"\", rev_tag = \"\"):\n",
    "    \n",
    "    # Add in stagger to handles in correct order\n",
    "    fwd_handle_new = fwd_tag + fwd_handle\n",
    "    rev_handle_new = rev_handle + str(Seq.Seq(rev_tag).reverse_complement())\n",
    "    \n",
    "    # Run QC with new handles\n",
    "    qc_seq,recs = process_fastq(data_file,fwd_handle_new,rev_handle_new)\n",
    "    index_updated,read_count,map_count,mapped,unmap_count,unmap,notfound_count,notfound = map_seqs(qc_seq,index, fullindex = fullindex, fwd = fwd_handle_new)\n",
    "    \n",
    "    print(f'Mapped % : {map_count/read_count}')\n",
    "    print(f'Unmapped % : {unmap_count/read_count}')\n",
    "    print(f'No Handle % : {notfound_count/read_count}')\n",
    "    \n",
    "    \n",
    "    return index_updated,read_count,map_count,mapped,unmap_count,unmap,notfound_count,notfound\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71bdc361-7882-4199-9f9e-6f633927c3b2",
   "metadata": {},
   "source": [
    "____________________________________________ TESTING SCRIPTS _________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac2c116-0683-4632-80b6-dd1262c1b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index,full = load_index(\"DNA_ALL_SEQUENCES_INDEX_cleaned_ext.csv\",trim = \"CTCATCTCAGAAGAGGATCTGGGC\",Fedit = \"\",Redit = \"C\", rev = True)\n",
    "\n",
    "inddf = pd.DataFrame.from_dict(index,'index')\n",
    "inddf.to_csv('crosscheck2.csv',index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba142646-5665-4775-9ce1-535aba92d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fastq_file = \"/Volumes/Connor 1TB/20221229_AEV_Screen_GZ/AEV_6/AEV_6_S86_L003_R2_001.fastq.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dea6de89-00f9-4351-a322-287e8ca4d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_file = \"/Volumes/Connor 1TB/20221229_AEV_Screen_GZ/AEV_6/AEV_6_S86_L003_R2_001.fastq.gz\"\n",
    "\n",
    "records = SeqIO.parse(gzip.open(fastq_file,'rt'),'fastq')\n",
    "with open('tempdata_6.fastq','w') as fq:\n",
    "    count = 0\n",
    "    newrecs = []\n",
    "    for r in records:\n",
    "        newrecs.append(r)\n",
    "        count += 1\n",
    "        \n",
    "        if count > 1e4:\n",
    "            break\n",
    "    SeqIO.write(newrecs,fq,'fastq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9390a16-d99a-467b-a64d-e92b3c75b84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCCCAGATCCTCTTCTGAGATGAG\n"
     ]
    }
   ],
   "source": [
    "rev = str(Seq.Seq(\"CTCATCTCAGAAGAGGATCTGGGC\").reverse_complement())\n",
    "\n",
    "qc_seq,recs = process_fastq('tempdata.fastq',\"CTCGAGACCTCCAGATCCACCAGA\",rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "50d28724-9841-4457-882f-dc6d75962d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_update,r,m,mapped,u,unmap,nf,nope = map_seqs(qc_seq,index,fullindex = full,fwd = \"CTCGAGACCTCCAGATCCACCAGA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd50a50-27a4-44e1-a23b-e81dbdc8f333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "398b7788-b2d6-4561-b338-8de02a451259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped % : 0.8211077844311377\n",
      "Unmapped % : 0.1528193612774451\n",
      "No Handle % : 0.026072854291417164\n",
      "['ACTCGAGACCTCCAGATCCACCAGACATCTGCAGGTGCTTCTTCCTCAGGATGATCAGGGTCACCAGCAGCAGGCCGATCAGCAGGGTGCTCAAGATAACTAACACAGAAATGCTGCCGCTGCCGCCGCTGCCGCTGCCGCCGCCCAGAT', 'ACTCGAGACCTCCAGATCCACCAGAGTACAGATATGTGCTCAGGCCGGCGGTGCCCATGATCACGGCAGCGGCCACAACTGTAATAATCACGATGCTGCCGCTGCCGCCGCTGCCGCTGCCGCCGCCCAGATCCTCTTCTGAGATGAGAC', 'ACTCGAGACCTCCAGATCCACCAGACAGCTTCTCCATCCTCTGGTGGCTGATCAGCAGGGTGCCCAGCAGCAGGATGCTGCTGCTGATGATCACGGGCACGATAACATATAATCCAGCAGAGCCGCTGCCGCCGCTGCCGCTGCCGACGC', 'ACTCGAGACCTCCAGATCCACCAGACCTCCACTGGAAGGTCAGGATCAGCAGGCTGATGCACAGGATCAGGCCCACGGCGATGTTGAACTTGAAGCCGAAAGGAAAAATAATGCTGCCGCTGCCGCCGCTGCCGCTGCCGCCGCCCAGAT', 'ACTCGAGACCTCCAGATCCACCAGAAACGAAAAAGGCGCTCACCACCAGGGCCAGGGTGCAGCCCAGCACCCAAGAAACTGTTAAAACAGAGCCGCTGCCGCCGCTGCCGCTGCCGCCGCCCAGATCCTATTCTGAGATGAGACGAAGAT', 'ACTCGAGACCTCCAGATCCACCAGACTTGTGCCACCTCTGCAGCCTCAGAGCAAGCAGCACGATCACGAAGGCCAGGAACACGCAGCTCACGGCAGCAACAGCAACAACTAAAGATCCAGAGCCGCCGCTGCCGCTGCCGCCGCCTAGAT', 'ACTCGAGACCTCCAGATCCACCAGAGGCGATCATCAGGAAGGTGATGCTGTAGCACAGGAAGATGCCGGTAAGTAACACATAAGAAAGGCTGCCGCTGCCGCCGCTGCCGCTGCCGCCGCCCAGATCCTCTTCTGAATGAGACGAAGATC', 'ACTCGAGACCTCCAGATCCACCAGACAGGAAGTTCAGCACGGCGAACTCCAGCAGGGCGCAGAAGCAGAAAACAAAACAAATGGCGATGCTGCCGCTGCCGCCGCTGTCGCTGCCGCCGCCCAGATCCTCTTCTGAGATGAGACGA', 'ACTCGAGACCTCCAGATCCACCAGAGCCAAGCAGCACGGCCACGAAGGCCAGGAACACGCAGCTGATAGCAGCAACAGCAACAACTAAAGATCCAGAGCCGCCGCTGCCGCTGCCGCCGCCCAGATCCTCTTCTGAGATGAGACGA', 'ACTCGAGACCTCCAGATCCACCAGAGTGCCTGCACCTCACGCAAAAGAAGATGCCCAGGCCGATGAACAGCAGCAGGCCGGCAACGCCGCCTAAAACAATTAAAGCCATGCTGCCGCTGCCGCCGCTGCCGCTGCCGCCGTCCAGATCCT']\n"
     ]
    }
   ],
   "source": [
    "print(f'Mapped % : {m/r}')\n",
    "print(f'Unmapped % : {u/r}')\n",
    "print(f'No Handle % : {nf/r}')\n",
    "print(unmap[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "353c38ce-28fb-429c-968f-68da67e98226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped % : 0.8381585192216422\n",
      "Unmapped % : 0.1330090175605126\n",
      "No Handle % : 0.02883246321784528\n"
     ]
    }
   ],
   "source": [
    "f = \"tempdata.fastq\"\n",
    "index1,full = load_index(\"DNA_ALL_SEQUENCES_INDEX_cleaned_ext.csv\",trim = \"CTCATCTCAGAAGAGGATCTGGGC\",Fedit = \"\",Redit = \"C\", rev = True)\n",
    "update_index1,read1,map_c1,map1,unmap_c1,unmap1,nf_c1,notfound1 = load_and_run(f, index1, fullindex = full, fwd_handle = \"TCGAGACCTCCAGATCCACCAGA\", rev_handle = \"GCCCAGATCCTCTTCTGAGATGAG\",fwd_tag = \"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25a2c2e9-afbd-48c8-aa01-7f79b8dba772",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/connorcall/Library/CloudStorage/GoogleDrive-cccall@stanford.edu/Shared drives/Gao Lab/Connor Call/Lab Python\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ed2f3f1-a1de-4a5e-b7e2-25d96d07b153",
   "metadata": {},
   "source": [
    "\n",
    "________________________________________________________________ RUN STARTS HERE ______________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5194109d-d1bd-4bf0-87a3-21bdd9997305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/connorcall/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/connorcall/miniconda3/lib/python3.10/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped % : 0.8076971964908833\n",
      "Unmapped % : 0.14241784793516873\n",
      "No Handle % : 0.04988495557394797\n",
      "Mapped % : 0.011071331441531032\n",
      "Unmapped % : 0.0021132109163767383\n",
      "No Handle % : 0.9868154576420922\n"
     ]
    }
   ],
   "source": [
    "## 1 and 2 Unind, Unb\n",
    "## 3 and 4 Unind, Bound\n",
    "## 5 and 6 Ind, Unb\n",
    "## 7 and 8 Ind, Bound\n",
    "\n",
    "## Load in data file names\n",
    "\n",
    "files = [[\"AEV_1_S81_L003_R2_001.fastq.gz\",\"AEV_2_S82_L003_R2_001.fastq.gz\"],[\"AEV_3_S83_L003_R2_001.fastq.gz\",\"AEV_4_S84_L003_R2_001.fastq.gz\"]\n",
    "         ,[\"AEV_5_S85_L003_R2_001.fastq.gz\",\"AEV_6_S86_L003_R2_001.fastq.gz\"],[\"AEV_7_S87_L003_R2_001.fastq.gz\",\"AEV_8_S88_L003_R2_001.fastq.gz\"]]\n",
    "outfiles = [\"AEV_1_2_data.csv\",\"AEV_3_4_data.csv\",\"AEV_5_6_data.csv\",\"AEV_7_8_data.csv\"]\n",
    "for f,out in zip([files[0]],[outfiles[0]]):\n",
    "    ## Load in Index and make a trimmed and full sequence index\n",
    "    index1,full = load_index(\"DNA_ALL_SEQUENCES_INDEX_cleaned_ext.csv\",trim = \"CTCATCTCAGAAGAGGATCTGGGC\",rev = True)\n",
    "    index2 = deepcopy(index1)\n",
    "    os.chdir(\"/Volumes/Connor 1TB/20221229_AEV_Screen_GZ/AEV_1\")\n",
    "    update_index1,read1,map_c1,map1,unmap_c1,unmap1,nf_c1,notfound1 = load_and_run(f[0], index1, fullindex = full, fwd_handle = \"CTCGAGACCTCCAGATCCACCAGA\", rev_handle = \"GCCCAGATCCTCTTCTGAGATGAG\")\n",
    "    os.chdir(\"/Volumes/Connor 1TB/20221229_AEV_Screen_GZ/AEV_2\")\n",
    "    update_index2,read2,map_c2,map2,unmap_c2,unmap2,nf_c2,notfound2 = load_and_run(f[1], index2, fullindex = full, fwd_handle = \"CTCGAGACCTCCAGATCCACCAGA\", rev_handle = \"GCCCAGATCCTCTTCTGAGATGAG\")\n",
    "    \n",
    "    final_return(out,index1 = update_index1, index2 = update_index2, num_reads = [read1,read2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "604b3362-2c52-4bfe-a16d-0b72d4516b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped % : 0.8426672994779307\n",
      "Unmapped % : 0.12850023730422402\n",
      "No Handle % : 0.02883246321784528\n",
      "Mapped % : 0.8426672994779307\n",
      "Unmapped % : 0.12850023730422402\n",
      "No Handle % : 0.02883246321784528\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['ID'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m update_index1,read1,map_c1,map1,unmap_c1,unmap1,nf_c1,notfound1 \u001b[38;5;241m=\u001b[39m load_and_run(f, index1, fullindex \u001b[38;5;241m=\u001b[39m full, fwd_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCTCGAGACCTCCAGATCCACCAGA\u001b[39m\u001b[38;5;124m\"\u001b[39m, rev_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGCCCAGATCCTCTTCTGAGATGAG\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m update_index2,read2,map_c2,map2,unmap_c2,unmap2,nf_c2,notfound2 \u001b[38;5;241m=\u001b[39m load_and_run(f, index2, fullindex \u001b[38;5;241m=\u001b[39m full, fwd_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCTCGAGACCTCCAGATCCACCAGA\u001b[39m\u001b[38;5;124m\"\u001b[39m, rev_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGCCCAGATCCTCTTCTGAGATGAG\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mfinal_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mupdate_index1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mupdate_index2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_reads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mread2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 125\u001b[0m, in \u001b[0;36mfinal_return\u001b[0;34m(fileout, index1, index2, num_reads)\u001b[0m\n\u001b[1;32m    122\u001b[0m     rep_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(rep_index,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m,columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRead Count Rep 2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRead Norm Rep 2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    123\u001b[0m     rep_df_trim \u001b[38;5;241m=\u001b[39m rep_df\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRead Norm Rep 2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 125\u001b[0m     output_df \u001b[38;5;241m=\u001b[39m \u001b[43moutput_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrep_df_trim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fileout,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    127\u001b[0m     output_df\u001b[38;5;241m.\u001b[39mto_csv(f,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,index_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/frame.py:9979\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m   9816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\n\u001b[1;32m   9817\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9818\u001b[0m     other: DataFrame \u001b[38;5;241m|\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[DataFrame \u001b[38;5;241m|\u001b[39m Series],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9824\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   9825\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9826\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   9827\u001b[0m \u001b[38;5;124;03m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[1;32m   9828\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9977\u001b[0m \u001b[38;5;124;03m    5  K1  A5   B1\u001b[39;00m\n\u001b[1;32m   9978\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 9979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_join_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrsuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9985\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9987\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/frame.py:10018\u001b[0m, in \u001b[0;36mDataFrame._join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m  10008\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  10009\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m  10010\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10011\u001b[0m             other,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10016\u001b[0m             validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m  10017\u001b[0m         )\n\u001b[0;32m> 10018\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10019\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m  10024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m  10025\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10026\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10028\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10029\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m  10030\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/reshape/merge.py:124\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    110\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    111\u001b[0m         left,\n\u001b[1;32m    112\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/reshape/merge.py:775\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m    773\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 775\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/reshape/merge.py:729\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    726\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft[:]\n\u001b[1;32m    727\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright[:]\n\u001b[0;32m--> 729\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m \u001b[43m_items_overlap_with_suffix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffixes\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    738\u001b[0m         join_index,\n\u001b[1;32m    739\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    745\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/reshape/merge.py:2458\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2455\u001b[0m lsuffix, rsuffix \u001b[38;5;241m=\u001b[39m suffixes\n\u001b[1;32m   2457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lsuffix \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rsuffix:\n\u001b[0;32m-> 2458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns overlap but no suffix specified: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto_rename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrenamer\u001b[39m(x, suffix):\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2462\u001b[0m \u001b[38;5;124;03m    Rename the left and right indices.\u001b[39;00m\n\u001b[1;32m   2463\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2474\u001b[0m \u001b[38;5;124;03m    x : renamed column name\u001b[39;00m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['ID'], dtype='object')"
     ]
    }
   ],
   "source": [
    "f = \"tempdata.fastq\"\n",
    "out = \"testfile_out.csv\"\n",
    "\n",
    "## Load in Index and make a trimmed and full sequence index\n",
    "index1,full = load_index(\"DNA_ALL_SEQUENCES_INDEX_cleaned_ext.csv\",trim = \"CTCATCTCAGAAGAGGATCTGGGC\",Fedit = \"\",Redit = \"C\", rev = True)\n",
    "index2,full2 = load_index(\"DNA_ALL_SEQUENCES_INDEX_cleaned_ext.csv\",trim = \"CTCATCTCAGAAGAGGATCTGGGC\",Fedit = \"\",Redit = \"GAAT\", rev = True)\n",
    "update_index1,read1,map_c1,map1,unmap_c1,unmap1,nf_c1,notfound1 = load_and_run(f, index1, fullindex = full, fwd_handle = \"TCGAGACCTCCAGATCCACCAGA\", rev_handle = \"GCCCAGATCCTCTTCTGAGATGAG\")\n",
    "update_index2,read2,map_c2,map2,unmap_c2,unmap2,nf_c2,notfound2 = load_and_run(f, index2, fullindex = full, fwd_handle = \"TCGAGACCTCCAGATCCACCAGA\", rev_handle = \"GCCCAGATCCTCTTCTGAGATGAG\")\n",
    "    \n",
    "final_return(out,index1 = update_index1, index2 = update_index2, num_reads = [read1,read2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "424d6d37-7f71-4ecf-a4c5-c60b7073b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_return(out,index1 = update_index1, index2 = update_index2, num_reads = [read1,read2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb689d71-d661-4a2e-b87b-19d841b4147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_return(outfiles[0],index1 = update_index1, index2 = update_index2, num_reads = [read1,read2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa0ee70c-b36c-41b0-87aa-31177bec90fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f39bd-65de-4d3b-affb-702607f2e069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86388c-d993-4523-9845-7c30ba25777d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde42a4-0e61-4f3a-b303-100c54090a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d3b57-3f48-45d9-8c7a-97207816dc00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede0549-980e-4221-9108-6ccd70283eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb59e3-c52f-46ff-ba07-b7a3e792fed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b649dc7-677c-49cb-bdbd-92df51444604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
